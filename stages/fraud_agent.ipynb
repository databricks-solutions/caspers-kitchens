{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2be128f4-c802-4fe3-930c-4e5e8ec1d10c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "#### fraud detection agent\n\nthis notebook creates an agent with tools to detect and flag fraudulent transactions"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ffc7e90-b728-4e83-8cad-3eda46e941e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Tool & View Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e0583b-b9cf-41d7-aa21-9bc159ca4da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS ${CATALOG}.ai;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a140cb0f-afb5-4c1a-8417-6191aedd8fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%sql\nCREATE OR REPLACE FUNCTION ${CATALOG}.ai.get_transaction_details(tid STRING COMMENT 'transaction id of the transaction')\nRETURNS TABLE (\n  body STRING COMMENT 'Body of the event',\n  event_type STRING COMMENT 'The type of event',\n  transaction_id STRING COMMENT 'The transaction id',\n  ts STRING COMMENT 'The timestamp of the event',\n  branch STRING COMMENT 'the branch where the transaction occurred'\n)\nCOMMENT 'Returns all events associated with the transaction id (tid)'\nRETURN\n  SELECT ae.body, ae.event_type, ae.transaction_id, ae.ts, br.name as branch\n  FROM ${CATALOG}.lakeflow.all_events ae\n  LEFT JOIN ${CATALOG}.simulator.branches br ON ae.branch_id = br.branch_id\n  WHERE ae.transaction_id = tid;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d1bf76-afca-4d7d-86e3-0b78bdfaf467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%sql\nCREATE OR REPLACE FUNCTION ${CATALOG}.ai.get_transaction_processing_time(tid STRING COMMENT 'transaction id of the transaction')\nRETURNS TABLE (\n  transaction_id STRING COMMENT 'The transaction id',\n  creation_time TIMESTAMP COMMENT 'The timestamp of the first event for the transaction',\n  completion_time TIMESTAMP COMMENT 'The timestamp of the last event for the transaction',\n  duration_seconds FLOAT COMMENT 'The total duration from the first to the last event in seconds'\n)\nCOMMENT 'Returns the first event time, last event time, and total duration for a given transaction id.'\nRETURN\n  WITH MinMaxTimestamps AS (\n    SELECT\n      MIN(try_to_timestamp(ts)) as first_event_time,\n      MAX(try_to_timestamp(ts)) as last_event_time\n    FROM\n      ${CATALOG}.lakeflow.all_events\n    WHERE\n      transaction_id = tid\n  )\n  SELECT\n    tid as transaction_id,\n    first_event_time AS creation_time,\n    last_event_time AS completion_time,\n    CAST(\n      (UNIX_TIMESTAMP(last_event_time) - UNIX_TIMESTAMP(first_event_time)) AS FLOAT\n    ) AS duration_seconds\n  FROM\n    MinMaxTimestamps;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1707682-0913-44bd-b05b-90547ee230fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%sql\nCREATE OR REPLACE VIEW ${CATALOG}.ai.transaction_patterns_per_branch_view AS\nWITH transaction_times AS (\n  SELECT\n    ae.transaction_id,\n    br.name as branch,\n    MAX(CASE WHEN ae.event_type = 'transaction_created' THEN try_to_timestamp(ae.ts) END) AS transaction_created_time,\n    MAX(CASE WHEN ae.event_type = 'transaction_completed' THEN try_to_timestamp(ae.ts) END) AS transaction_completed_time,\n    MAX(CASE WHEN ae.event_type = 'fraud_check_completed' THEN try_to_timestamp(ae.ts) END) AS fraud_check_time\n  FROM\n    ${CATALOG}.lakeflow.all_events ae\n  LEFT JOIN ${CATALOG}.simulator.branches br ON ae.branch_id = br.branch_id\n  WHERE\n    try_to_timestamp(ae.ts) >= CURRENT_TIMESTAMP() - INTERVAL 1 DAY\n  GROUP BY\n    ae.transaction_id,\n    br.name\n),\ntotal_transaction_times AS (\n  SELECT\n    transaction_id,\n    branch,\n    (UNIX_TIMESTAMP(transaction_completed_time) - UNIX_TIMESTAMP(transaction_created_time)) / 60 AS total_transaction_time_minutes,\n    (UNIX_TIMESTAMP(fraud_check_time) - UNIX_TIMESTAMP(transaction_created_time)) AS fraud_check_duration_seconds\n  FROM\n    transaction_times\n  WHERE\n    transaction_created_time IS NOT NULL\n    AND transaction_completed_time IS NOT NULL\n)\nSELECT\n  branch,\n  PERCENTILE(total_transaction_time_minutes, 0.50) AS P50_minutes,\n  PERCENTILE(total_transaction_time_minutes, 0.75) AS P75_minutes,\n  PERCENTILE(total_transaction_time_minutes, 0.99) AS P99_minutes,\n  AVG(fraud_check_duration_seconds) AS avg_fraud_check_seconds\nFROM\n  total_transaction_times\nGROUP BY\n  branch"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32eca549-67b1-4dc0-9e1a-3e9f131c0e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%sql\nCREATE OR REPLACE FUNCTION ${CATALOG}.ai.get_branch_patterns(br STRING COMMENT 'Branch name as a string')\nRETURNS TABLE (\n  branch STRING COMMENT 'Branch name',\n  P50_minutes FLOAT COMMENT '50th percentile transaction time in minutes',\n  P75_minutes FLOAT COMMENT '75th percentile transaction time in minutes',\n  P99_minutes FLOAT COMMENT '99th percentile transaction time in minutes',\n  avg_fraud_check_seconds FLOAT COMMENT 'Average fraud check duration in seconds'\n)\nCOMMENT 'Returns transaction timing patterns and fraud check durations for a specific branch'\nRETURN\n  SELECT branch, P50_minutes, P75_minutes, P99_minutes, avg_fraud_check_seconds\n  FROM ${CATALOG}.ai.transaction_patterns_per_branch_view AS tpb\n  WHERE tpb.branch = br;"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7f5e202-58a3-462e-9f2c-2b61b4366f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05805ea8-65b7-49c1-90c7-ce255c257ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c1a6e2-fc53-4337-b919-957896f2322d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
    "LLM_MODEL = dbutils.widgets.get(\"LLM_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e226ce-f3ee-4522-82fd-8bdf7121f999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def writefilev(line, cell):\n",
    "    \"\"\"\n",
    "    %%writefilev file.py\n",
    "    Allows {{var}} substitutions while leaving normal {} intact.\n",
    "    \"\"\"\n",
    "    filename = line.strip()\n",
    "\n",
    "    def replacer(match):\n",
    "        expr = match.group(1)\n",
    "        return str(eval(expr, globals(), locals()))\n",
    "\n",
    "    # Replace only double braces {{var}}\n",
    "    content = re.sub(r\"\\{\\{(.*?)\\}\\}\", replacer, cell)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"Wrote file with substitutions: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ddd9df-5f1c-42ea-9446-196558fd5b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "%%writefilev agent.py\nfrom typing import Any, Generator, Optional, Sequence, Union\n\nimport mlflow\nfrom databricks_langchain import (\n    ChatDatabricks,\n    VectorSearchRetrieverTool,\n    DatabricksFunctionClient,\n    UCFunctionToolkit,\n    set_uc_function_client,\n)\nfrom langchain_core.language_models import LanguageModelLike\nfrom langchain_core.runnables import RunnableConfig, RunnableLambda\nfrom langchain_core.tools import BaseTool\nfrom langgraph.graph import END, StateGraph\nfrom langgraph.graph.graph import CompiledGraph\nfrom langgraph.graph.state import CompiledStateGraph\nfrom langgraph.prebuilt.tool_node import ToolNode\nfrom mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\nfrom mlflow.pyfunc import ChatAgent\nfrom mlflow.types.agent import (\n    ChatAgentChunk,\n    ChatAgentMessage,\n    ChatAgentResponse,\n    ChatContext,\n)\n\nmlflow.langchain.autolog()\n\nclient = DatabricksFunctionClient()\nset_uc_function_client(client)\n\n############################################\n# Define your LLM endpoint and system prompt\n############################################\nLLM_ENDPOINT_NAME = f\"{{LLM_MODEL}}\"\nllm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n\nsystem_prompt = \"\"\"You are FraudDetectorGPT, a banking security agent responsible for analyzing transactions for potential fraud.\n\n    You can call tools to gather the information you need. Start with a `transaction_id`.\n\n    Instructions:\n    1. Call `get_transaction_details(transaction_id)` first to get event history and confirm the id is valid and the transaction was processed.\n    2. Analyze the transaction processing time by calling `get_transaction_processing_time(transaction_id)`.\n    3. Extract the branch information (either directly or from the event body).\n    4. Call `get_branch_patterns(branch)` to get typical transaction patterns for that branch.\n    5. Compare this transaction's characteristics to typical patterns to identify anomalies.\n\n    Fraud indicators to look for:\n    - Unusually fast processing times (bypassing normal checks)\n    - Transactions outside normal branch patterns\n    - Multiple rapid transactions\n    - Unusual amounts or frequencies\n\n    Output a single-line JSON with these fields:\n    - `fraud_risk_score` (float 0.0-1.0, where 1.0 is highest risk),\n    - `fraud_classification` (\"none\" | \"low\" | \"medium\" | \"high\"),\n    - `reason` (short human explanation of why this transaction is flagged or cleared)\n\n    You must return only the JSON. No extra text or markdown.\"\"\"\n\n###############################################################################\n## Define tools for your agent, enabling it to retrieve data or take actions\n## beyond text generation\n## To create and see usage examples of more tools, see\n## https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html\n###############################################################################\ntools = []\n\nuc_tool_names = [f\"{{CATALOG}}.ai.get_transaction_details\", \n                 f\"{{CATALOG}}.ai.get_branch_patterns\",\n                 f\"{{CATALOG}}.ai.get_transaction_processing_time\"]\nuc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\ntools.extend(uc_toolkit.tools)\n\n#####################\n## Define agent logic\n#####################\n\n\ndef create_tool_calling_agent(\n    model: LanguageModelLike,\n    tools: Union[Sequence[BaseTool], ToolNode],\n    system_prompt: Optional[str] = None,\n) -> CompiledGraph:\n    model = model.bind_tools(tools)\n\n    # Define the function that determines which node to go to\n    def should_continue(state: ChatAgentState):\n        messages = state[\"messages\"]\n        last_message = messages[-1]\n        # If there are function calls, continue. else, end\n        if last_message.get(\"tool_calls\"):\n            return \"continue\"\n        else:\n            return \"end\"\n\n    if system_prompt:\n        preprocessor = RunnableLambda(\n            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n            + state[\"messages\"]\n        )\n    else:\n        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n    model_runnable = preprocessor | model\n\n    def call_model(\n        state: ChatAgentState,\n        config: RunnableConfig,\n    ):\n        response = model_runnable.invoke(state, config)\n\n        return {\"messages\": [response]}\n\n    workflow = StateGraph(ChatAgentState)\n\n    workflow.add_node(\"agent\", RunnableLambda(call_model))\n    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n\n    workflow.set_entry_point(\"agent\")\n    workflow.add_conditional_edges(\n        \"agent\",\n        should_continue,\n        {\n            \"continue\": \"tools\",\n            \"end\": END,\n        },\n    )\n    workflow.add_edge(\"tools\", \"agent\")\n\n    return workflow.compile()\n\n\nclass LangGraphChatAgent(ChatAgent):\n    def __init__(self, agent: CompiledStateGraph):\n        self.agent = agent\n\n    def predict(\n        self,\n        messages: list[ChatAgentMessage],\n        context: Optional[ChatContext] = None,\n        custom_inputs: Optional[dict[str, Any]] = None,\n    ) -> ChatAgentResponse:\n        request = {\"messages\": self._convert_messages_to_dict(messages)}\n\n        messages = []\n        for event in self.agent.stream(request, stream_mode=\"updates\"):\n            for node_data in event.values():\n                messages.extend(\n                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n                )\n        return ChatAgentResponse(messages=messages)\n\n    def predict_stream(\n        self,\n        messages: list[ChatAgentMessage],\n        context: Optional[ChatContext] = None,\n        custom_inputs: Optional[dict[str, Any]] = None,\n    ) -> Generator[ChatAgentChunk, None, None]:\n        request = {\"messages\": self._convert_messages_to_dict(messages)}\n        for event in self.agent.stream(request, stream_mode=\"updates\"):\n            for node_data in event.values():\n                yield from (\n                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n                )\n\n\n# Create the agent object, and specify it as the agent object to use when\n# loading the agent back for inference via mlflow.models.set_model()\nagent = create_tool_calling_agent(llm, tools, system_prompt)\nAGENT = LangGraphChatAgent(agent)\nmlflow.models.set_model(AGENT)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a909c3e-4fd0-4cdd-98af-93a7ccb3badb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# get an actual transaction_id\nsample_transaction_id = spark.sql(f\"\"\"\n    SELECT transaction_id \n    FROM {CATALOG}.lakeflow.all_events \n    WHERE event_type='transaction_completed'\n    LIMIT 1\n\"\"\").collect()[0]['transaction_id']"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c672421-c8d0-4252-92d1-576dd01f0f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "assert sample_transaction_id is not None\nprint(sample_transaction_id)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ee737e-0495-4856-a87a-60bac7baf043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "import mlflow\nfrom agent import LLM_ENDPOINT_NAME, tools\nfrom databricks_langchain import VectorSearchRetrieverTool\nfrom mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\nfrom pkg_resources import get_distribution\nfrom unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n\nresources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\nfor tool in tools:\n    resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n\ninput_example = {\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": f\"{sample_transaction_id}\"\n        }\n    ]\n}\n\nwith mlflow.start_run():\n    logged_agent_info = mlflow.pyfunc.log_model(\n        name=\"fraud_agent_v2\",\n        python_model=\"agent.py\",\n        input_example=input_example,\n        resources=resources,\n        pip_requirements=[\n            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n            f\"mlflow=={get_distribution('mlflow').version}\",\n            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n            f\"langgraph=={get_distribution('langgraph').version}\",\n        ],\n    )\n\nmlflow.set_active_model(model_id = logged_agent_info.model_id)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c5ffb0-ed1b-4e86-809e-9b7af90656e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72348da2-fd71-4413-8e0a-5cb16ed03d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# sample 10 transaction_ids\nfraud_queries = [\n    row['transaction_id'] for row in spark.sql(f\"\"\"\n        SELECT transaction_id \n        FROM {CATALOG}.lakeflow.all_events \n        WHERE event_type='transaction_completed'\n        LIMIT 10\n    \"\"\").collect()\n]\n\n# wrap in correct input schema\ndata = []\nfor query in fraud_queries:\n    data.append(\n        {\n            \"inputs\": {\n                \"messages\": [\n                    {\n                        \"role\": \"user\",\n                        \"content\": query,\n                    }\n                ]\n            },\n        }\n    )\n\nprint(data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfcf41db-e682-4ef3-964d-e5c40a07983c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# create guideline, run evals\n\nfrom mlflow.genai.scorers import Guidelines\nimport mlflow\nimport sys\nimport os\nsys.path.append(os.getcwd())\n\nnotebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\nproject_directory = os.path.dirname(notebook_path)\n\n# Add the project directory to the system path\nsys.path.append(project_directory)\n\nfrom agent import AGENT\n\nfraud_detection_guideline = Guidelines(\n    name=\"fraud_detection_reason\",\n    guidelines=[\"Fraud risk assessments must be based on transaction patterns and timing anomalies, not on customer identity or demographics.\"]\n)\n\n\nresults = mlflow.genai.evaluate(\n    data=data,\n    scorers=[fraud_detection_guideline],\n    predict_fn = lambda messages: AGENT.predict({\"messages\": messages})\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f870d6-05d0-478e-8784-98793ba8480c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "#### log fraud detector to `UC`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "273249df-a966-45fc-9ddf-d7138af804b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "mlflow.set_registry_uri(\"databricks-uc\")\n\nUC_MODEL_NAME = f\"{CATALOG}.ai.fraud_detector\"\n\n# register the model to UC\nuc_registered_model_info = mlflow.register_model(\n    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf715fb3-953c-4516-8d07-79c0d362a99e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### deploy the agent to model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c0d2d9-6379-4e2c-84bf-9004dd74b6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "from databricks import agents\ndeployment_info = agents.deploy(\n    model_name=UC_MODEL_NAME, \n    model_version=uc_registered_model_info.version, \n    scale_to_zero=False,\n    endpoint_name=f\"{dbutils.widgets.get(\"FRAUD_AGENT_ENDPOINT_NAME\")}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212d8c67-af4d-48c9-88d8-aba01a22edb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(deployment_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a35fccd0-52e3-4efd-b345-83756040e098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### record model in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff483b29-ed19-4f2b-ba21-f398c0968ff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Also add to UC-state\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from uc_state import add\n",
    "\n",
    "add(dbutils.widgets.get(\"CATALOG\"), \"endpoints\", deployment_info)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5241498588668969,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "refunder_agent",
   "widgets": {
    "CATALOG": {
     "currentValue": "",
     "nuid": "ec6aab2b-9dae-46a5-a002-31181de04243",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "CATALOG",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "CATALOG",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "LLM_MODEL": {
     "currentValue": "",
     "nuid": "579d358e-a5e4-4925-afda-75dbb651c6c1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "LLM_MODEL",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "LLM_MODEL",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "REFUND_AGENT_ENDPOINT_NAME": {
     "currentValue": "",
     "nuid": "ccf262a5-2c34-435f-a8f3-ea86126c6353",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "REFUND_AGENT_ENDPOINT_NAME",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "REFUND_AGENT_ENDPOINT_NAME",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}