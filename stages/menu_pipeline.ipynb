{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Menu Document Processing Pipeline\n",
        "\n",
        "Deploys a DLT pipeline using a **bronze / silver / gold** medallion architecture:\n",
        "\n",
        "- **Bronze** — Raw ingestion from `brands_metadata`, `inspections`, and `violations` source\n",
        "  tables with DLT data-quality expectations (`@dlt.expect`) that enforce non-null keys and\n",
        "  valid value ranges.\n",
        "- **Silver** — Cleaned and enriched: price tiers, calorie categories, macronutrient ratios,\n",
        "  allergen counts (menus); pass/fail status, score bands, severity index (inspections);\n",
        "  urgency scoring and immediate-action flags (violations).\n",
        "- **Gold** — Business-ready tables consumed by the Genie space: `menu_items`,\n",
        "  `nutritional_info`, `allergens`, `brand_nutrition_summary`, `inspection_details`,\n",
        "  `violation_analysis`, `location_compliance_summary`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install --upgrade databricks-sdk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dbutils.library.restartPython()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CATALOG = dbutils.widgets.get(\"CATALOG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Deploy the document processing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service import pipelines\n",
        "\n",
        "w = WorkspaceClient()\n",
        "\n",
        "PIPELINE_NAME = \"Menu Document Processing Pipeline\"\n",
        "\n",
        "root_abs_path = os.path.abspath(\"../pipelines/menu_documents\")\n",
        "root_dbx_path = root_abs_path.replace(\n",
        "    os.environ.get(\"DATABRICKS_WORKSPACE_ROOT\", \"/Workspace\"),\n",
        "    \"/Workspace\"\n",
        ")\n",
        "\n",
        "pipeline_config = dict(\n",
        "    catalog=CATALOG,\n",
        "    schema=\"menu_documents\",\n",
        "    continuous=False,\n",
        "    name=PIPELINE_NAME,\n",
        "    serverless=True,\n",
        "    configuration={\"MENU_CATALOG\": CATALOG},\n",
        "    root_path=root_dbx_path,\n",
        "    libraries=[\n",
        "        pipelines.PipelineLibrary(\n",
        "            glob=pipelines.PathPattern(include=f\"{root_dbx_path}/**\")\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "existing = [\n",
        "    p for p in w.pipelines.list_pipelines(filter=f\"name LIKE '{PIPELINE_NAME}'\")\n",
        "    if p.name == PIPELINE_NAME\n",
        "]\n",
        "\n",
        "if existing:\n",
        "    pipeline_id = existing[0].pipeline_id\n",
        "    w.pipelines.update(pipeline_id=pipeline_id, **pipeline_config)\n",
        "    print(f\"Updated existing pipeline: {pipeline_id}\")\n",
        "else:\n",
        "    created = w.pipelines.create(**pipeline_config)\n",
        "    pipeline_id = created.pipeline_id\n",
        "    print(f\"Created new pipeline: {pipeline_id}\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('../utils')\n",
        "from uc_state import add\n",
        "add(CATALOG, \"pipelines\", {\"pipeline_id\": pipeline_id, \"name\": PIPELINE_NAME})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Trigger the pipeline and wait for completion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "\n",
        "update = w.pipelines.start_update(pipeline_id=pipeline_id)\n",
        "print(f\"Started pipeline update: {update.update_id}\")\n",
        "\n",
        "while True:\n",
        "    info = w.pipelines.get(pipeline_id=pipeline_id)\n",
        "    latest = info.latest_updates[0] if info.latest_updates else None\n",
        "    state_str = str(latest.state) if latest else \"STARTING\"\n",
        "    if \"COMPLETED\" in state_str:\n",
        "        print(f\"Pipeline finished: {state_str}\")\n",
        "        break\n",
        "    if \"FAILED\" in state_str:\n",
        "        raise RuntimeError(f\"Pipeline failed: {state_str}\")\n",
        "    if \"CANCELED\" in state_str:\n",
        "        raise RuntimeError(f\"Pipeline canceled: {state_str}\")\n",
        "    print(f\"  Pipeline state: {state_str}...\")\n",
        "    time.sleep(15)\n",
        "\n",
        "print(\"\\u2705 Menu pipeline stage complete\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}