# databricks.yml
bundle:
  name: caspers-bank

variables:
  catalog:
    description: "UC catalog for this bundle/target"
    default: caspersbankdev

workspace:
  # Default root path under your user home; still configurable per target
  root_path: /Workspace/Users/${workspace.current_user.userName}/caspers-bank-demo
  file_path: ${workspace.root_path}     # where files get synced

# Ship the repo files on deploy (adjust excludes as you like)
sync:
  include:
    - ./*
  exclude:
    - .git/**
    - .DS_Store
    - .claude/**
    - .databricks/**
    - ./data/universe/**

scripts:
  cleanup:
    content: |
      set -eo pipefail

      # Detect the target passed to `databricks bundle run cleanup -t <target>`
      TARGET_FLAG=""
      if env | grep -q '^DATABRICKS_BUNDLE_TARGET='; then
        TARGET_FLAG="-t $DATABRICKS_BUNDLE_TARGET"
      fi

      # Get fully-resolved bundle config (includes target overrides)
      RESOLVED_JSON="$(databricks bundle validate $TARGET_FLAG --output json)"

      # Pull values we need (requires jq)
      FILE_PATH="$(printf '%s' "$RESOLVED_JSON" | jq -r '.workspace.file_path // (.workspace.root_path + "/src")')"
      CATALOG="$(printf '%s' "$RESOLVED_JSON" | jq -r '.variables.catalog.value // .variables.catalog.default')"

      mkdir -p .bundle
      cat > .bundle/submit.json <<JSON
      {
        "run_name": "caspers_bank: cleanup (ephemeral)",
        "performance_target": "PERFORMANCE_OPTIMIZED",
        "tasks": [
          {
            "task_key": "destroy",
            "notebook_task": {
              "notebook_path": "$FILE_PATH/destroy",
              "source": "WORKSPACE",
              "base_parameters": { "CATALOG": "$CATALOG" }
            }
          }
        ]
      }
      JSON

      databricks jobs submit --json @.bundle/submit.json


targets:
  default:
    default: true

    resources:
      jobs:
        caspers_bank:
          name: "Casper's Bank Initializer"
          queue:
            enabled: true
          performance_target: PERFORMANCE_OPTIMIZED

          parameters:
            - name: CATALOG
              default: ${var.catalog}
            - name: EVENTS_VOLUME
              default: events
            - name: LLM_MODEL
              default: databricks-meta-llama-3-3-70b-instruct
            - name: FRAUD_AGENT_ENDPOINT_NAME
              default: caspers_fraud_agent
            - name: SIMULATOR_SCHEMA
              default: simulator
            - name: START_DAY
              default: "70"
            - name: SPEED_MULTIPLIER
              default: "60.0"
            - name: SCHEDULE_MINUTES
              default: "3"
            - name: PIPELINE_SCHEDULE_MINUTES
              default: "0"

          tasks:
            - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/canonical_data

            - task_key: Spark_Declarative_Pipeline
              depends_on:
                - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakeflow

            - task_key: Fraud_Detection_Agent
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/fraud_agent

            - task_key: Fraud_Detection_Stream
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/fraud_stream

            - task_key: Lakebase_Reverse_ETL
              depends_on:
                - task_key: Fraud_Detection_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakebase

            - task_key: Databricks_App_Transaction_Manager
              depends_on:
                - task_key: Lakebase_Reverse_ETL
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/apps

  fraud:
    resources:
      jobs:
        caspers_bank:
          name: "Casper's Bank Initializer"
          queue:
            enabled: true
          performance_target: PERFORMANCE_OPTIMIZED

          parameters:
            - name: CATALOG
              default: ${var.catalog}
            - name: EVENTS_VOLUME
              default: events
            - name: LLM_MODEL
              default: databricks-meta-llama-3-3-70b-instruct
            - name: DISPUTE_AGENT_ENDPOINT_NAME
              default: caspers_dispute_agent
            - name: DISPUTE_RATE
              default: "0.15"
            - name: SIMULATOR_SCHEMA
              default: simulator
            - name: START_DAY
              default: "70"
            - name: SPEED_MULTIPLIER
              default: "60.0"
            - name: SCHEDULE_MINUTES
              default: "3"
            - name: PIPELINE_SCHEDULE_MINUTES
              default: "0"

          tasks:
            - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/canonical_data

            - task_key: Spark_Declarative_Pipeline
              depends_on:
                - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakeflow

            - task_key: Dispute_Agent
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_agent

            - task_key: Dispute_Generator_Stream
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_generator_stream

            - task_key: Dispute_Agent_Stream
              depends_on:
                - task_key: Dispute_Agent
                - task_key: Dispute_Generator_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_agent_stream

            - task_key: Dispute_Lakebase
              depends_on:
                - task_key: Dispute_Agent_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_lakebase

  free:
    resources:
      jobs:
        caspers_bank:
          name: "Casper's Bank Initializer"
          queue:
            enabled: true
          performance_target: PERFORMANCE_OPTIMIZED

          parameters:
            - name: CATALOG
              default: ${var.catalog}
            - name: EVENTS_VOLUME
              default: events
            - name: SIMULATOR_SCHEMA
              default: simulator
            - name: START_DAY
              default: "70"
            - name: SPEED_MULTIPLIER
              default: "60.0"
            - name: SCHEDULE_MINUTES
              default: "3"
            - name: PIPELINE_SCHEDULE_MINUTES
              default: "3"

          tasks:
            - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/canonical_data

            - task_key: Spark_Declarative_Pipeline
              depends_on:
                - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakeflow

  all:
    resources:
      jobs:
        caspers_bank:
          name: "Casper's Bank Initializer"
          queue:
            enabled: true
          performance_target: PERFORMANCE_OPTIMIZED

          parameters:
            - name: CATALOG
              default: ${var.catalog}
            - name: EVENTS_VOLUME
              default: events
            - name: LLM_MODEL
              default: databricks-meta-llama-3-3-70b-instruct
            - name: FRAUD_AGENT_ENDPOINT_NAME
              default: caspers_fraud_agent
            - name: DISPUTE_AGENT_ENDPOINT_NAME
              default: caspers_dispute_agent
            - name: DISPUTE_RATE
              default: "0.15"
            - name: SIMULATOR_SCHEMA
              default: simulator
            - name: START_DAY
              default: "70"
            - name: SPEED_MULTIPLIER
              default: "60.0"
            - name: SCHEDULE_MINUTES
              default: "3"
            - name: PIPELINE_SCHEDULE_MINUTES
              default: "0"

          tasks:
            - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/canonical_data

            - task_key: Spark_Declarative_Pipeline
              depends_on:
                - task_key: Canonical_Data
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakeflow

            - task_key: Fraud_Detection_Agent
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/fraud_agent

            - task_key: Fraud_Detection_Stream
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/fraud_stream

            - task_key: Dispute_Agent
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_agent

            - task_key: Dispute_Generator_Stream
              depends_on:
                - task_key: Spark_Declarative_Pipeline
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_generator_stream

            - task_key: Dispute_Agent_Stream
              depends_on:
                - task_key: Dispute_Agent
                - task_key: Dispute_Generator_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_agent_stream

            - task_key: Dispute_Lakebase
              depends_on:
                - task_key: Dispute_Agent_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/dispute_lakebase

            - task_key: Lakebase_Reverse_ETL
              depends_on:
                - task_key: Fraud_Detection_Stream
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/lakebase

            - task_key: Databricks_App_Transaction_Manager
              depends_on:
                - task_key: Lakebase_Reverse_ETL
              notebook_task:
                notebook_path: ${workspace.root_path}/stages/apps